import { createAIConfig } from '@/config/ai.config'
import { PrismaDB } from '@/db'
import { generateUniqueBigIntId } from '@/utils'
import { inject, injectable } from 'inversify'
import OpenAI from 'openai'
import { v4 as uuidv4 } from 'uuid'
import fs from 'fs'
import path from 'path'
import sharp from 'sharp'

// å›¾ç‰‡æ•°æ®æ¥å£
interface ImageData {
  url: string
  type: string
}

// å›¾ç‰‡ä¼˜åŒ–å™¨ç±»
class ImageOptimizer {
  // æ™ºèƒ½å‹ç¼©å›¾ç‰‡
  async optimizeImage(inputPath: string, options: {
    maxWidth?: number
    maxHeight?: number
    quality?: number
    maxSizeKB?: number
    format?: 'jpeg' | 'png' | 'webp'
  } = {}): Promise<Buffer> {
    const {
      maxWidth = 1024,      // æœ€å¤§å®½åº¦
      maxHeight = 1024,     // æœ€å¤§é«˜åº¦
      quality = 80,         // å‹ç¼©è´¨é‡
      maxSizeKB = 100,      // æœ€å¤§æ–‡ä»¶å¤§å°(KB)
      format = 'jpeg'       // è¾“å‡ºæ ¼å¼
    } = options

    const startTime = Date.now()
    console.log(`[AI] ğŸ”§ å¼€å§‹Sharpå‹ç¼©: ${path.basename(inputPath)}`)
    console.log(`[AI] ğŸ“‹ å‹ç¼©å‚æ•°: æœ€å¤§å°ºå¯¸${maxWidth}x${maxHeight}, ç›®æ ‡å¤§å°${maxSizeKB}KB, æ ¼å¼${format}`)

    try {
      // è·å–åŸå§‹å›¾ç‰‡ä¿¡æ¯
      const originalStats = fs.statSync(inputPath)
      const originalSizeKB = originalStats.size / 1024
      console.log(`[AI] ğŸ“Š åŸå§‹å›¾ç‰‡: ${originalSizeKB.toFixed(1)}KB`)

      // è·å–å›¾ç‰‡å…ƒæ•°æ®
      const metadata = await sharp(inputPath).metadata()
      console.log(`[AI] ğŸ–¼ï¸  åŸå§‹å°ºå¯¸: ${metadata.width}x${metadata.height}, æ ¼å¼: ${metadata.format}`)

      let currentQuality = quality
      let compressedBuffer: Buffer
      let iterationCount = 0

      do {
        iterationCount++
        console.log(`[AI] ğŸ”„ å‹ç¼©è¿­ä»£ ${iterationCount}: è´¨é‡${currentQuality}%`)

        const sharpInstance = sharp(inputPath)
          .resize(maxWidth, maxHeight, {
            fit: 'inside',
            withoutEnlargement: true
          })

        // æ ¹æ®æ ¼å¼é€‰æ‹©å‹ç¼©æ–¹å¼
        if (format === 'jpeg') {
          compressedBuffer = await sharpInstance
            .jpeg({
              quality: currentQuality,
              progressive: true,
              mozjpeg: true  // æ›´å¥½çš„å‹ç¼©
            })
            .toBuffer()
        } else if (format === 'png') {
          compressedBuffer = await sharpInstance
            .png({
              quality: currentQuality,
              compressionLevel: 9
            })
            .toBuffer()
        } else {
          compressedBuffer = await sharpInstance
            .webp({
              quality: currentQuality
            })
            .toBuffer()
        }

        const sizeKB = compressedBuffer.length / 1024
        const compressionRatio = ((originalSizeKB - sizeKB) / originalSizeKB * 100).toFixed(1)

        console.log(`[AI] ğŸ“‰ è¿­ä»£${iterationCount}ç»“æœ: ${sizeKB.toFixed(1)}KB (å‹ç¼©${compressionRatio}%)`)

        if (sizeKB <= maxSizeKB) {
          console.log(`[AI] âœ… è¾¾åˆ°ç›®æ ‡å¤§å°ï¼Œå‹ç¼©å®Œæˆ`)
          break
        }

        if (currentQuality <= 20) {
          console.log(`[AI] âš ï¸  å·²è¾¾æœ€ä½è´¨é‡(20%)ï¼Œåœæ­¢å‹ç¼©`)
          break
        }

        currentQuality -= 10 // é™ä½è´¨é‡
        console.log(`[AI] ğŸ”½ é™ä½è´¨é‡åˆ° ${currentQuality}%`)

      } while (currentQuality > 20)

      const endTime = Date.now()
      const processingTime = endTime - startTime
      const finalSizeKB = compressedBuffer.length / 1024
      const finalCompressionRatio = ((originalSizeKB - finalSizeKB) / originalSizeKB * 100).toFixed(1)

      console.log(`[AI] ğŸ‰ Sharpå‹ç¼©å®Œæˆ!`)
      console.log(`[AI] â±ï¸  å¤„ç†æ—¶é—´: ${processingTime}ms`)
      console.log(`[AI] ğŸ“Š å‹ç¼©ç»“æœ: ${originalSizeKB.toFixed(1)}KB â†’ ${finalSizeKB.toFixed(1)}KB`)
      console.log(`[AI] ğŸ“ˆ å‹ç¼©æ¯”ä¾‹: ${finalCompressionRatio}%`)
      console.log(`[AI] ğŸ”§ æœ€ç»ˆè´¨é‡: ${currentQuality}%`)
      console.log(`[AI] ğŸ”„ è¿­ä»£æ¬¡æ•°: ${iterationCount}`)

      return compressedBuffer

    } catch (error: any) {
      const endTime = Date.now()
      const processingTime = endTime - startTime
      console.error(`[AI] âŒ Sharpå‹ç¼©å¤±è´¥ (${processingTime}ms): ${error.message}`)
      throw new Error(`å›¾ç‰‡å‹ç¼©å¤±è´¥: ${error.message}`)
    }
  }

  // è®¡ç®—é¢„ä¼°Tokenæ•°
  estimateTokens(imageSizeKB: number): number {
    // ç»éªŒå…¬å¼: 1KBå›¾ç‰‡ â‰ˆ 1000-1500 tokens
    const baseTokens = imageSizeKB * 1200
    const base64Overhead = baseTokens * 0.33 // Base64å¢åŠ 33%
    const totalTokens = Math.ceil(baseTokens + base64Overhead)

    console.log(`[AI] ğŸ§® Tokenä¼°ç®—: ${imageSizeKB.toFixed(1)}KB â†’ ${baseTokens.toLocaleString()}åŸºç¡€tokens + ${Math.ceil(baseTokens * 0.33).toLocaleString()}Base64å¼€é”€ = ${totalTokens.toLocaleString()}æ€»tokens`)

    return totalTokens
  }

  // è‡ªé€‚åº”å‹ç¼©åˆ°ç›®æ ‡Tokenæ•°
  async compressToTokenLimit(inputPath: string, maxTokens: number = 30000): Promise<Buffer> {
    console.log(`[AI] ğŸ¯ å¼€å§‹è‡ªé€‚åº”å‹ç¼©åˆ°ç›®æ ‡Tokenæ•°`)
    console.log(`[AI] ğŸ“‹ ç›®æ ‡é™åˆ¶: ${maxTokens.toLocaleString()} tokens`)

    // ä¿å®ˆä¼°ç®—ç›®æ ‡æ–‡ä»¶å¤§å°
    const targetSizeKB = Math.floor(maxTokens / 1500) // ä¿å®ˆä¼°ç®—
    console.log(`[AI] ğŸ“Š è®¡ç®—ç›®æ ‡å¤§å°: ${maxTokens.toLocaleString()} tokens Ã· 1500 = ${targetSizeKB}KB`)

    const startTime = Date.now()

    try {
      const compressedBuffer = await this.optimizeImage(inputPath, {
        maxWidth: 1024,
        maxHeight: 1024,
        maxSizeKB: targetSizeKB,
        quality: 85
      })

      const actualSizeKB = compressedBuffer.length / 1024
      const estimatedTokens = this.estimateTokens(actualSizeKB)
      const endTime = Date.now()
      const processingTime = endTime - startTime

      console.log(`[AI] ğŸ‰ è‡ªé€‚åº”å‹ç¼©å®Œæˆ!`)
      console.log(`[AI] â±ï¸  æ€»å¤„ç†æ—¶é—´: ${processingTime}ms`)
      console.log(`[AI] ğŸ“Š æœ€ç»ˆç»“æœ: ${actualSizeKB.toFixed(1)}KB`)
      console.log(`[AI] ğŸ¯ é¢„ä¼°tokens: ${estimatedTokens.toLocaleString()} (ç›®æ ‡: ${maxTokens.toLocaleString()})`)

      if (estimatedTokens <= maxTokens) {
        console.log(`[AI] âœ… æˆåŠŸè¾¾åˆ°tokené™åˆ¶ç›®æ ‡!`)
      } else {
        console.log(`[AI] âš ï¸  ç•¥è¶…tokené™åˆ¶ï¼Œä½†å·²å°½åŠ›å‹ç¼©`)
      }

      return compressedBuffer

    } catch (error: any) {
      const endTime = Date.now()
      const processingTime = endTime - startTime
      console.error(`[AI] âŒ è‡ªé€‚åº”å‹ç¼©å¤±è´¥ (${processingTime}ms): ${error.message}`)
      throw error
    }
  }
}

// AI æœåŠ¡ï¼šå°è£… DeepSeek(OpenAI å…¼å®¹) çš„åŒæ­¥ä¸æµå¼è°ƒç”¨
@injectable()
export class AIService {
  private client: OpenAI
  private model: string
  private visionModel: string
  private imageOptimizer: ImageOptimizer

  constructor(@inject(PrismaDB) private readonly PrismaDB: PrismaDB) {
    const cfg = createAIConfig()
    // åˆå§‹åŒ– OpenAI SDK å®¢æˆ·ç«¯ï¼ˆDeepSeek å…¼å®¹ OpenAI æ¥å£ï¼‰
    this.client = new OpenAI({ apiKey: cfg.apiKey, baseURL: cfg.baseURL })
    this.model = cfg.model
    this.visionModel = cfg.visionModel
    this.imageOptimizer = new ImageOptimizer()
  }

  // åŸºç¡€é—®ç­”ï¼ˆä¸€æ¬¡æ€§è¿”å›ï¼‰
  public async chat(
    message: string,
    conversationId?: string
  ): Promise<{ reply: string; conversationId: string }> {
    const convId = conversationId || uuidv4()
    const completion = await this.client.chat.completions.create({
      model: this.model,
      messages: [{ role: 'user', content: message }],
      temperature: 0.7,
    })
    const reply = completion.choices?.[0]?.message?.content?.trim() || ''
    return { reply, conversationId: convId }
  }

  // å¤šæ¨¡æ€é—®ç­”ï¼ˆæ”¯æŒå›¾ç‰‡+æ–‡æœ¬ï¼‰
  public async chatWithImages(
    message: string,
    images: ImageData[] = [],
    conversationId?: string
  ): Promise<{ reply: string; conversationId: string }> {
    const convId = conversationId || uuidv4()

    try {
      // é¢„æ£€æŸ¥tokené™åˆ¶
      let totalImageSize = 0
      let estimatedTokens = 0

      for (const image of images) {
        if (image.url.startsWith('/static/')) {
          const filePath = path.resolve(process.cwd(), image.url.substring(1))
          if (fs.existsSync(filePath)) {
            const stats = fs.statSync(filePath)
            totalImageSize += stats.size
            estimatedTokens += Math.floor(stats.size * 1.33 * 0.75)
          }
        }
      }

      estimatedTokens += (message?.length || 0) * 0.75

      console.log(`[AI] éæµå¼Tokenä¼°ç®— - å›¾ç‰‡å¤§å°: ${(totalImageSize/1024/1024).toFixed(1)}MB, é¢„ä¼°tokens: ${estimatedTokens.toLocaleString()}`)

      // å¦‚æœè¶…è¿‡tokené™åˆ¶ï¼Œä½¿ç”¨å‹ç¼©ç­–ç•¥
      const MAX_CONTEXT_TOKENS = 130000
      let processedImages = images

      if (estimatedTokens > MAX_CONTEXT_TOKENS) {
        console.log(`[AI] é¢„ä¼°tokensè¶…é™ï¼Œä½¿ç”¨å‹ç¼©ç­–ç•¥`)
        processedImages = await this.compressImagesForTokenLimit(images)

        if (processedImages.length === 0) {
          throw new Error('å›¾ç‰‡æ–‡ä»¶è¿‡å¤§ï¼Œæ— æ³•å¤„ç†ã€‚è¯·ä¸Šä¼ è¾ƒå°çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆå»ºè®®å°äº500KBï¼‰ã€‚')
        }
      }

      // æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
      const content: any[] = []

      // æ·»åŠ æ–‡æœ¬å†…å®¹
      if (message && message.trim()) {
        content.push({
          type: 'text',
          text: message
        })
      }

      // æ·»åŠ å›¾ç‰‡å†…å®¹ - ä½¿ç”¨DeepSeek Vision APIæ ¼å¼
      for (const image of processedImages) {
        const imageBase64Data = await this.processImageToBase64ForDeepSeek(image.url, image.type)
        if (imageBase64Data) {
          content.push({
            type: 'image',
            image: {
              data: imageBase64Data,
              format: 'base64'
            }
          })
        }
      }

      // å¦‚æœæ²¡æœ‰ä»»ä½•å†…å®¹ï¼Œä½¿ç”¨é»˜è®¤æç¤º
      if (content.length === 0) {
        content.push({
          type: 'text',
          text: 'è¯·æè¿°è¿™äº›å›¾ç‰‡çš„å†…å®¹'
        })
      }

      console.log(`[AI] å¤šæ¨¡æ€å¯¹è¯ - æ–‡æœ¬é•¿åº¦: ${message?.length || 0}, å›¾ç‰‡æ•°é‡: ${images.length}`)
      console.log(`[AI] ğŸš€ ========== å‡†å¤‡è°ƒç”¨DeepSeek Vision API ==========`)
      console.log(`[AI] ğŸ“‹ æ¶ˆæ¯æ ¼å¼éªŒè¯:`)
      console.log(`[AI]    - å†…å®¹é¡¹æ•°: ${content.length}`)
      console.log(`[AI]    - æ¨¡å‹: ${this.visionModel}`)

      // ç»Ÿè®¡æ¶ˆæ¯å†…å®¹
      let textItems = 0
      let imageItems = 0
      for (const item of content) {
        if (item.type === 'text') textItems++
        if (item.type === 'image') imageItems++
      }
      console.log(`[AI]    - æ–‡æœ¬é¡¹: ${textItems}`)
      console.log(`[AI]    - å›¾ç‰‡é¡¹: ${imageItems}`)

      // è®¡ç®—æ¶ˆæ¯å¤§å°
      const messageContent = JSON.stringify(content)
      const messageSizeKB = Buffer.byteLength(messageContent, 'utf8') / 1024
      console.log(`[AI]    - æ¶ˆæ¯å¤§å°: ${messageSizeKB.toFixed(1)}KB`)

      console.log(`[AI] ğŸ“¡ å‘é€APIè¯·æ±‚...`)
      const apiStartTime = Date.now()

      const completion = await this.client.chat.completions.create({
        model: this.visionModel, // ä½¿ç”¨è§†è§‰æ¨¡å‹
        messages: [{
          role: 'user',
          content: messageContent // DeepSeekéœ€è¦JSONå­—ç¬¦ä¸²æ ¼å¼
        }],
        temperature: 0.7,
        max_tokens: 1000
      })

      const apiEndTime = Date.now()
      const apiResponseTime = apiEndTime - apiStartTime
      console.log(`[AI] âœ… APIå“åº”æˆåŠŸ (è€—æ—¶: ${apiResponseTime}ms)`)

      const reply = completion.choices?.[0]?.message?.content?.trim() || ''

      console.log(`[AI] ğŸ‰ ========== DeepSeek Vision APIå“åº”æˆåŠŸ ==========`)
      console.log(`[AI] ğŸ“Š å“åº”ç»Ÿè®¡:`)
      console.log(`[AI]    - å›å¤é•¿åº¦: ${reply.length}å­—ç¬¦`)
      console.log(`[AI]    - å›å¤é¢„è§ˆ: "${reply.substring(0, 100)}${reply.length > 100 ? '...' : ''}"`)

      if (completion.usage) {
        console.log(`[AI] ğŸ’° Tokenä½¿ç”¨æƒ…å†µ:`)
        console.log(`[AI]    - è¾“å…¥tokens: ${completion.usage.prompt_tokens?.toLocaleString() || 'N/A'}`)
        console.log(`[AI]    - è¾“å‡ºtokens: ${completion.usage.completion_tokens?.toLocaleString() || 'N/A'}`)
        console.log(`[AI]    - æ€»tokens: ${completion.usage.total_tokens?.toLocaleString() || 'N/A'}`)
      }

      console.log(`[AI] âœ… éæµå¼å¤šæ¨¡æ€å¯¹è¯å®Œæˆ`)

      return { reply, conversationId: convId }

    } catch (error: any) {
      console.error('[AI] å¤šæ¨¡æ€å¯¹è¯å¤±è´¥:', error.message)
      throw new Error(`å›¾ç‰‡åˆ†æå¤±è´¥: ${error.message}`)
    }
  }

  // æµå¼é—®ç­”ï¼šé€æ®µè¿”å›å†…å®¹ï¼Œä¾› SSE å†™å…¥
  public async streamChat(
    message: string,
    onDelta: (text: string) => void,
    opts?: { signal?: AbortSignal }
  ): Promise<{ conversationId: string }> {
    const convId = uuidv4()
    const stream = await this.client.chat.completions.create({
      model: this.model,
      messages: [{ role: 'user', content: message }],
      temperature: 0.7,
      stream: true,
      // @ts-ignore openai sdk å…è®¸é€ä¼  signal
      signal: opts?.signal,
    } as any)

    // é€å—è¯»å–ï¼šä»…ä½¿ç”¨ delta.contentï¼Œé¿å…æœ€ç»ˆ message.content å†æ¬¡ç´¯åŠ å¯¼è‡´é‡å¤
    for await (const chunk of stream as any) {
      const delta = chunk?.choices?.[0]?.delta?.content
      if (delta) onDelta(delta)
    }

    return { conversationId: convId }
  }

  // æµå¼å¤šæ¨¡æ€é—®ç­”ï¼ˆæ”¯æŒå›¾ç‰‡+æ–‡æœ¬ï¼‰
  // æ³¨æ„ï¼šDeepSeek Vision APIçš„æµå¼æ”¯æŒå¯èƒ½æœ‰é™åˆ¶ï¼Œä½¿ç”¨é™çº§ç­–ç•¥
  public async streamChatWithImages(
    message: string,
    images: ImageData[] = [],
    onDelta: (text: string) => void,
    opts?: { signal?: AbortSignal }
  ): Promise<{ conversationId: string }> {
    const convId = uuidv4()

    try {
      console.log(`[AI] æµå¼å¤šæ¨¡æ€å¯¹è¯è¯·æ±‚ - æ–‡æœ¬é•¿åº¦: ${message?.length || 0}, å›¾ç‰‡æ•°é‡: ${images.length}`)

      // æ£€æŸ¥å›¾ç‰‡å¤§å°å’Œtokenä¼°ç®—
      console.log(`[AI] ğŸ” ========== æµå¼å¤šæ¨¡æ€å¯¹è¯é¢„æ£€æŸ¥ ==========`)
      console.log(`[AI] ğŸ“ æ–‡æœ¬æ¶ˆæ¯: "${message?.substring(0, 50)}${(message?.length || 0) > 50 ? '...' : ''}"`)
      console.log(`[AI] ğŸ“¸ å›¾ç‰‡æ•°é‡: ${images.length}`)

      let totalImageSize = 0
      let estimatedTokens = 0

      for (let i = 0; i < images.length; i++) {
        const image = images[i]
        console.log(`[AI] ğŸ–¼ï¸  æ£€æŸ¥å›¾ç‰‡${i+1}: ${image.url}`)

        if (image.url.startsWith('/static/')) {
          const filePath = path.resolve(process.cwd(), image.url.substring(1))
          if (fs.existsSync(filePath)) {
            const stats = fs.statSync(filePath)
            const sizeKB = stats.size / 1024
            const sizeMB = sizeKB / 1024
            totalImageSize += stats.size

            // ä¼°ç®—Base64åçš„tokenæ•°é‡ï¼šæ–‡ä»¶å¤§å° * 1.33 (Base64è†¨èƒ€) * 0.75 (tokenä¼°ç®—)
            const imageTokens = Math.floor(stats.size * 1.33 * 0.75)
            estimatedTokens += imageTokens

            console.log(`[AI]    - å¤§å°: ${sizeKB.toFixed(1)}KB (${sizeMB.toFixed(2)}MB)`)
            console.log(`[AI]    - é¢„ä¼°tokens: ${imageTokens.toLocaleString()}`)
          } else {
            console.warn(`[AI]    - âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: ${filePath}`)
          }
        } else {
          console.log(`[AI]    - ğŸ“ éæœ¬åœ°æ–‡ä»¶ï¼Œè·³è¿‡å¤§å°æ£€æŸ¥`)
        }
      }

      // æ·»åŠ æ–‡æœ¬æ¶ˆæ¯çš„tokenä¼°ç®—
      const textTokens = Math.floor((message?.length || 0) * 0.75)
      estimatedTokens += textTokens

      console.log(`[AI] ğŸ“Š Tokené¢„ä¼°ç®—ç»“æœ:`)
      console.log(`[AI]    - å›¾ç‰‡æ€»å¤§å°: ${(totalImageSize/1024/1024).toFixed(2)}MB`)
      console.log(`[AI]    - å›¾ç‰‡tokens: ${(estimatedTokens - textTokens).toLocaleString()}`)
      console.log(`[AI]    - æ–‡æœ¬tokens: ${textTokens.toLocaleString()}`)
      console.log(`[AI]    - æ€»é¢„ä¼°tokens: ${estimatedTokens.toLocaleString()}`)

      // DeepSeekæ¨¡å‹æœ€å¤§ä¸Šä¸‹æ–‡ï¼š131,072 tokensï¼Œé¢„ç•™1000ç»™å›å¤
      const MAX_CONTEXT_TOKENS = 130000
      console.log(`[AI] ğŸ¯ æ¨¡å‹é™åˆ¶: ${MAX_CONTEXT_TOKENS.toLocaleString()} tokens`)
      console.log(`[AI] ğŸ“ˆ Tokenä½¿ç”¨ç‡: ${((estimatedTokens/MAX_CONTEXT_TOKENS)*100).toFixed(1)}%`)

      if (estimatedTokens > MAX_CONTEXT_TOKENS) {
        const excessTokens = estimatedTokens - MAX_CONTEXT_TOKENS
        console.log(`[AI] âŒ Tokenè¶…é™æ£€æµ‹:`)
        console.log(`[AI]    - é¢„ä¼°tokens: ${estimatedTokens.toLocaleString()}`)
        console.log(`[AI]    - æ¨¡å‹é™åˆ¶: ${MAX_CONTEXT_TOKENS.toLocaleString()}`)
        console.log(`[AI]    - è¶…å‡ºtokens: ${excessTokens.toLocaleString()}`)
        console.log(`[AI] ğŸ—œï¸  å¯åŠ¨Sharpå‹ç¼©ç­–ç•¥...`)
        return await this.streamChatWithImagesCompressed(message, images, onDelta, opts)
      }

      // å¦‚æœå›¾ç‰‡æ€»å¤§å°è¶…è¿‡1MBï¼Œä½¿ç”¨éæµå¼é™çº§ç­–ç•¥
      const MAX_STREAM_IMAGE_SIZE = 1 * 1024 * 1024 // 1MB
      if (totalImageSize > MAX_STREAM_IMAGE_SIZE) {
        console.log(`[AI] ğŸ“Š æ–‡ä»¶å¤§å°æ£€æŸ¥:`)
        console.log(`[AI]    - å›¾ç‰‡æ€»å¤§å°: ${(totalImageSize/1024/1024).toFixed(2)}MB`)
        console.log(`[AI]    - æµå¼é™åˆ¶: ${(MAX_STREAM_IMAGE_SIZE/1024/1024).toFixed(1)}MB`)
        console.log(`[AI] ğŸ”„ ä½¿ç”¨éæµå¼é™çº§ç­–ç•¥...`)
        return await this.streamChatWithImagesNonStreaming(message, images, onDelta, opts)
      }

      console.log(`[AI] âœ… é¢„æ£€æŸ¥é€šè¿‡ï¼Œä½¿ç”¨æ­£å¸¸æµå¼å¤„ç†`)
      console.log(`[AI] ========== é¢„æ£€æŸ¥å®Œæˆ ==========`)

      // å°è¯•æµå¼å¤šæ¨¡æ€å¯¹è¯
      try {
        return await this.attemptStreamingVision(message, images, onDelta, opts, convId)
      } catch (streamError: any) {
        console.warn(`[AI] æµå¼å¤šæ¨¡æ€å¯¹è¯å¤±è´¥ï¼Œå°è¯•é™çº§ç­–ç•¥: ${streamError.message}`)

        // å¦‚æœæµå¼å¤±è´¥ï¼Œä½¿ç”¨éæµå¼é™çº§ç­–ç•¥
        return await this.streamChatWithImagesNonStreaming(message, images, onDelta, opts)
      }

    } catch (error: any) {
      console.error('[AI] æµå¼å¤šæ¨¡æ€å¯¹è¯å®Œå…¨å¤±è´¥:', error.message)
      throw new Error(`å›¾ç‰‡åˆ†æå¤±è´¥: ${error.message}`)
    }
  }

  // å°è¯•çœŸæ­£çš„æµå¼è§†è§‰å¯¹è¯
  private async attemptStreamingVision(
    message: string,
    images: ImageData[],
    onDelta: (text: string) => void,
    opts?: { signal?: AbortSignal },
    convId?: string
  ): Promise<{ conversationId: string }> {
    const conversationId = convId || uuidv4()

    // æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
    const content: any[] = []

    // æ·»åŠ æ–‡æœ¬å†…å®¹
    if (message && message.trim()) {
      content.push({
        type: 'text',
        text: message
      })
    }

    // æ·»åŠ å›¾ç‰‡å†…å®¹ - ä½¿ç”¨DeepSeek Vision APIæ ¼å¼
    for (const image of images) {
      const imageBase64Data = await this.processImageToBase64ForDeepSeek(image.url, image.type)
      if (imageBase64Data) {
        content.push({
          type: 'image',
          image: {
            data: imageBase64Data,
            format: 'base64'
          }
        })
      }
    }

    // å¦‚æœæ²¡æœ‰ä»»ä½•å†…å®¹ï¼Œä½¿ç”¨é»˜è®¤æç¤º
    if (content.length === 0) {
      content.push({
        type: 'text',
        text: 'è¯·æè¿°è¿™äº›å›¾ç‰‡çš„å†…å®¹'
      })
    }

    console.log(`[AI] å°è¯•æµå¼è§†è§‰å¯¹è¯ - å†…å®¹é¡¹æ•°: ${content.length}`)

    const stream = await this.client.chat.completions.create({
      model: this.visionModel,
      messages: [{
        role: 'user',
        content: JSON.stringify(content) // DeepSeekéœ€è¦JSONå­—ç¬¦ä¸²æ ¼å¼
      }],
      temperature: 0.7,
      max_tokens: 800, // å‡å°‘tokenæ•°é‡
      stream: true,
      // @ts-ignore openai sdk å…è®¸é€ä¼  signal
      signal: opts?.signal,
    } as any)

    // é€å—è¯»å–ï¼šä»…ä½¿ç”¨ delta.content
    for await (const chunk of stream as any) {
      const delta = chunk?.choices?.[0]?.delta?.content
      if (delta) onDelta(delta)
    }

    return { conversationId }
  }

  // å‹ç¼©å›¾ç‰‡å¤„ç†ç­–ç•¥ï¼šå‹ç¼©å›¾ç‰‡åè¿›è¡Œåˆ†æ
  private async streamChatWithImagesCompressed(
    message: string,
    images: ImageData[],
    onDelta: (text: string) => void,
    opts?: { signal?: AbortSignal }
  ): Promise<{ conversationId: string }> {
    console.log('[AI] ä½¿ç”¨å›¾ç‰‡å‹ç¼©ç­–ç•¥è¿›è¡Œåˆ†æ')

    // å‹ç¼©å›¾ç‰‡æ•°æ®
    const compressedImages = await this.compressImagesForTokenLimit(images)

    if (compressedImages.length === 0) {
      // å¦‚æœå‹ç¼©åæ²¡æœ‰å›¾ç‰‡ï¼Œé™çº§ä¸ºçº¯æ–‡æœ¬å¯¹è¯
      console.log('[AI] å›¾ç‰‡å‹ç¼©å¤±è´¥ï¼Œé™çº§ä¸ºçº¯æ–‡æœ¬å¯¹è¯')
      onDelta('æŠ±æ­‰ï¼Œå›¾ç‰‡æ–‡ä»¶è¿‡å¤§æ— æ³•å¤„ç†ã€‚è¯·å°è¯•ä¸Šä¼ è¾ƒå°çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆå»ºè®®å°äº1MBï¼‰ã€‚')
      return { conversationId: uuidv4() }
    }

    // ä½¿ç”¨å‹ç¼©åçš„å›¾ç‰‡è¿›è¡Œéæµå¼åˆ†æï¼Œç„¶åæ¨¡æ‹Ÿæµå¼è¾“å‡º
    const { reply, conversationId } = await this.chatWithImages(message, compressedImages)

    // æ¨¡æ‹Ÿæµå¼è¾“å‡º
    const words = reply.split('')
    const chunkSize = Math.max(1, Math.floor(words.length / 50))

    for (let i = 0; i < words.length; i += chunkSize) {
      if (opts?.signal?.aborted) {
        throw new Error('Request aborted')
      }

      const chunk = words.slice(i, i + chunkSize).join('')
      onDelta(chunk)
      await new Promise(resolve => setTimeout(resolve, 50))
    }

    return { conversationId }
  }

  // éæµå¼é™çº§ç­–ç•¥ï¼šå…ˆè·å–å®Œæ•´å›å¤ï¼Œç„¶åæ¨¡æ‹Ÿæµå¼è¾“å‡º
  private async streamChatWithImagesNonStreaming(
    message: string,
    images: ImageData[],
    onDelta: (text: string) => void,
    opts?: { signal?: AbortSignal }
  ): Promise<{ conversationId: string }> {
    console.log('[AI] ä½¿ç”¨éæµå¼é™çº§ç­–ç•¥è¿›è¡Œå›¾ç‰‡åˆ†æ')

    // ä½¿ç”¨éæµå¼å¤šæ¨¡æ€å¯¹è¯è·å–å®Œæ•´å›å¤
    const { reply, conversationId } = await this.chatWithImages(message, images)

    // æ¨¡æ‹Ÿæµå¼è¾“å‡º
    const words = reply.split('')
    const chunkSize = Math.max(1, Math.floor(words.length / 50)) // åˆ†æˆçº¦50ä¸ªå—

    for (let i = 0; i < words.length; i += chunkSize) {
      // æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
      if (opts?.signal?.aborted) {
        throw new Error('Request aborted')
      }

      const chunk = words.slice(i, i + chunkSize).join('')
      onDelta(chunk)

      // æ·»åŠ å°å»¶è¿Ÿæ¨¡æ‹ŸçœŸå®æµå¼æ•ˆæœ
      await new Promise(resolve => setTimeout(resolve, 50))
    }

    return { conversationId }
  }

  // ä¿å­˜ AI å¯¹è¯è®°å½•ï¼ˆåœ¨æ§åˆ¶å™¨é‡Œæ‹¿åˆ°å®Œæ•´å›å¤åè°ƒç”¨ï¼‰
  public async saveConversation(userId: string, message: string, response: string): Promise<void> {
    // å¢åŠ å¯è§‚æµ‹æ—¥å¿—ï¼Œé¿å…æ³„éœ²å†…å®¹ï¼Œä»…æ‰“å°é•¿åº¦ä¸ç”¨æˆ·ID
    if (!userId) {
      console.warn('[AI] saveConversation skipped: empty userId')
      return
    }
    try {
      console.log(
        `[AI] saveConversation try: userId=${userId}, qLen=${message?.length || 0}, aLen=${response?.length || 0}`
      )
      await this.PrismaDB.prisma.aiConversation.create({
        data: {
          id: generateUniqueBigIntId(true) as string,
          userId,
          message,
          response,
        },
      } as any)
      console.log('[AI] saveConversation success')
    } catch (e: any) {
      console.warn('[AI] saveConversation failed:', e?.message)
      throw e
    }
  }

  // è·å–æœ€è¿‘ N æ¡å¯¹è¯
  public async getRecentConversations(userId: string, limit = 10) {
    if (!userId) return []
    const list = await this.PrismaDB.prisma.aiConversation.findMany({
      where: { userId },
      orderBy: { createdAt: 'desc' },
      take: limit,
    })
    return list
  }

  /**
   * å‹ç¼©å›¾ç‰‡ä»¥é€‚åº”tokené™åˆ¶ï¼ˆä½¿ç”¨SharpçœŸå®å‹ç¼©ï¼‰
   * @param images åŸå§‹å›¾ç‰‡æ•°ç»„
   * @returns å‹ç¼©åçš„å›¾ç‰‡æ•°ç»„
   */
  private async compressImagesForTokenLimit(images: ImageData[]): Promise<ImageData[]> {
    const compressedImages: ImageData[] = []
    const MAX_TOKENS_PER_IMAGE = 30000 // æ¯å¼ å›¾ç‰‡æœ€å¤§30K tokens
    const startTime = Date.now()

    console.log(`[AI] ğŸ—œï¸ ========== å¼€å§‹Sharpæ™ºèƒ½å‹ç¼© ==========`)
    console.log(`[AI] ğŸ“‹ å‹ç¼©ä»»åŠ¡: ${images.length} å¼ å›¾ç‰‡`)
    console.log(`[AI] ğŸ¯ ç›®æ ‡é™åˆ¶: ${MAX_TOKENS_PER_IMAGE.toLocaleString()} tokens/å¼ `)
    console.log(`[AI] â° å¼€å§‹æ—¶é—´: ${new Date().toLocaleTimeString()}`)

    for (let i = 0; i < images.length; i++) {
      const image = images[i]
      const imageStartTime = Date.now()

      console.log(`[AI] ğŸ“¸ ========== å¤„ç†å›¾ç‰‡ ${i+1}/${images.length} ==========`)
      console.log(`[AI] ğŸ“‚ å›¾ç‰‡è·¯å¾„: ${image.url}`)

      try {
        if (image.url.startsWith('/static/')) {
          const originalPath = path.resolve(process.cwd(), image.url.substring(1))
          console.log(`[AI] ğŸ” å®Œæ•´è·¯å¾„: ${originalPath}`)

          if (!fs.existsSync(originalPath)) {
            console.warn(`[AI] âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: ${originalPath}`)
            continue
          }

          // è·å–åŸå§‹æ–‡ä»¶ä¿¡æ¯
          const originalStats = fs.statSync(originalPath)
          const originalSizeKB = originalStats.size / 1024
          const originalSizeMB = originalSizeKB / 1024
          const originalTokens = this.imageOptimizer.estimateTokens(originalSizeKB)

          console.log(`[AI] ğŸ“Š åŸå§‹å›¾ç‰‡ä¿¡æ¯:`)
          console.log(`[AI]    - æ–‡ä»¶å¤§å°: ${originalSizeKB.toFixed(1)}KB (${originalSizeMB.toFixed(2)}MB)`)
          console.log(`[AI]    - é¢„ä¼°tokens: ${originalTokens.toLocaleString()}`)
          console.log(`[AI]    - æ–‡ä»¶ç±»å‹: ${image.type}`)

          if (originalTokens <= MAX_TOKENS_PER_IMAGE) {
            // å›¾ç‰‡å·²ç»è¶³å¤Ÿå°ï¼Œç›´æ¥ä½¿ç”¨
            console.log(`[AI] âœ… å›¾ç‰‡${i+1}å·²ç¬¦åˆè¦æ±‚ï¼Œæ— éœ€å‹ç¼©`)
            console.log(`[AI] ğŸ“ˆ Tokenä½¿ç”¨ç‡: ${((originalTokens/MAX_TOKENS_PER_IMAGE)*100).toFixed(1)}%`)
            compressedImages.push(image)
          } else {
            // éœ€è¦å‹ç¼©
            const excessTokens = originalTokens - MAX_TOKENS_PER_IMAGE
            const compressionNeeded = ((excessTokens / originalTokens) * 100).toFixed(1)

            console.log(`[AI] ğŸ”„ å›¾ç‰‡${i+1}éœ€è¦å‹ç¼©:`)
            console.log(`[AI]    - å½“å‰tokens: ${originalTokens.toLocaleString()}`)
            console.log(`[AI]    - ç›®æ ‡tokens: ${MAX_TOKENS_PER_IMAGE.toLocaleString()}`)
            console.log(`[AI]    - è¶…å‡ºtokens: ${excessTokens.toLocaleString()}`)
            console.log(`[AI]    - éœ€å‹ç¼©: ${compressionNeeded}%`)

            try {
              // ä½¿ç”¨Sharpè¿›è¡Œæ™ºèƒ½å‹ç¼©
              console.log(`[AI] ğŸš€ å¯åŠ¨Sharpå‹ç¼©å¼•æ“...`)
              const compressedBuffer = await this.imageOptimizer.compressToTokenLimit(originalPath, MAX_TOKENS_PER_IMAGE)

              // ç”Ÿæˆå‹ç¼©åçš„ä¸´æ—¶æ–‡ä»¶
              const timestamp = Date.now()
              const tempFileName = `compressed_${timestamp}_${i}_${Math.random().toString(36).substr(2, 6)}.jpg`
              const tempFilePath = path.resolve(process.cwd(), 'static/IMAGE', tempFileName)

              console.log(`[AI] ğŸ’¾ ä¿å­˜å‹ç¼©å›¾ç‰‡: ${tempFileName}`)
              console.log(`[AI] ğŸ“‚ ä¿å­˜è·¯å¾„: ${tempFilePath}`)

              // ä¿å­˜å‹ç¼©åçš„å›¾ç‰‡
              fs.writeFileSync(tempFilePath, compressedBuffer)

              // éªŒè¯ä¿å­˜çš„æ–‡ä»¶
              const savedStats = fs.statSync(tempFilePath)
              const savedSizeKB = savedStats.size / 1024
              const savedTokens = this.imageOptimizer.estimateTokens(savedSizeKB)

              console.log(`[AI] âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ:`)
              console.log(`[AI]    - ä¿å­˜å¤§å°: ${savedSizeKB.toFixed(1)}KB`)
              console.log(`[AI]    - é¢„ä¼°tokens: ${savedTokens.toLocaleString()}`)
              console.log(`[AI]    - å‹ç¼©æ¯”ä¾‹: ${((originalSizeKB - savedSizeKB) / originalSizeKB * 100).toFixed(1)}%`)
              console.log(`[AI]    - Tokenå‡å°‘: ${((originalTokens - savedTokens) / originalTokens * 100).toFixed(1)}%`)

              // åˆ›å»ºæ–°çš„å›¾ç‰‡æ•°æ®å¯¹è±¡
              const compressedImage: ImageData = {
                url: `/static/IMAGE/${tempFileName}`,
                type: 'image/jpeg' // å‹ç¼©åç»Ÿä¸€ä¸ºJPEGæ ¼å¼
              }

              compressedImages.push(compressedImage)

              const imageEndTime = Date.now()
              const imageProcessingTime = imageEndTime - imageStartTime
              console.log(`[AI] ğŸ‰ å›¾ç‰‡${i+1}å‹ç¼©æˆåŠŸ! (è€—æ—¶: ${imageProcessingTime}ms)`)

            } catch (compressError: any) {
              const imageEndTime = Date.now()
              const imageProcessingTime = imageEndTime - imageStartTime
              console.error(`[AI] âŒ å›¾ç‰‡${i+1}å‹ç¼©å¤±è´¥ (è€—æ—¶: ${imageProcessingTime}ms):`)
              console.error(`[AI]    - é”™è¯¯ä¿¡æ¯: ${compressError.message}`)
              console.error(`[AI]    - é”™è¯¯å †æ ˆ: ${compressError.stack}`)
              console.log(`[AI] ğŸ”„ è·³è¿‡æ­¤å›¾ç‰‡ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€å¼ `)
            }
          }
        } else {
          // éæœ¬åœ°æ–‡ä»¶ï¼Œç›´æ¥æ·»åŠ ï¼ˆå‡è®¾å·²ç»æ˜¯åˆé€‚å¤§å°ï¼‰
          console.log(`[AI] ğŸ“ éæœ¬åœ°å›¾ç‰‡ï¼Œç›´æ¥ä½¿ç”¨: ${image.url}`)
          compressedImages.push(image)
        }
      } catch (error: any) {
        const imageEndTime = Date.now()
        const imageProcessingTime = imageEndTime - imageStartTime
        console.error(`[AI] âŒ å¤„ç†å›¾ç‰‡${i+1}å¼‚å¸¸ (è€—æ—¶: ${imageProcessingTime}ms):`)
        console.error(`[AI]    - é”™è¯¯ä¿¡æ¯: ${error.message}`)
        console.error(`[AI]    - å›¾ç‰‡è·¯å¾„: ${image.url}`)
      }

      console.log(`[AI] ========== å›¾ç‰‡ ${i+1} å¤„ç†å®Œæˆ ==========`)
    }

    const endTime = Date.now()
    const totalProcessingTime = endTime - startTime

    console.log(`[AI] ğŸ‰ ========== Sharpå‹ç¼©ä»»åŠ¡å®Œæˆ ==========`)
    console.log(`[AI] â° ç»“æŸæ—¶é—´: ${new Date().toLocaleTimeString()}`)
    console.log(`[AI] â±ï¸  æ€»è€—æ—¶: ${totalProcessingTime}ms (${(totalProcessingTime/1000).toFixed(1)}ç§’)`)
    console.log(`[AI] ğŸ“Š å¤„ç†ç»“æœ: ${compressedImages.length}/${images.length} å¼ å›¾ç‰‡å¯ç”¨`)
    console.log(`[AI] ğŸ“ˆ æˆåŠŸç‡: ${((compressedImages.length/images.length)*100).toFixed(1)}%`)

    if (compressedImages.length === 0) {
      console.warn(`[AI] âš ï¸  è­¦å‘Š: æ²¡æœ‰å›¾ç‰‡å¯ç”¨äºAIåˆ†æ`)
    } else {
      console.log(`[AI] âœ… å‡†å¤‡å°† ${compressedImages.length} å¼ å‹ç¼©å›¾ç‰‡å‘é€ç»™DeepSeek Vision API`)
    }

    return compressedImages
  }

  /**
   * å¤„ç†å›¾ç‰‡è½¬æ¢ä¸ºDeepSeek Vision APIæ ¼å¼çš„Base64æ•°æ®
   * @param imageUrl å›¾ç‰‡URLæˆ–è·¯å¾„
   * @param mimeType MIMEç±»å‹
   */
  private async processImageToBase64ForDeepSeek(imageUrl: string, mimeType: string): Promise<string | null> {
    try {
      // å¦‚æœå·²ç»æ˜¯Base64æ ¼å¼ï¼Œæå–çº¯Base64æ•°æ®
      if (imageUrl.startsWith('data:')) {
        console.log('[AI] å›¾ç‰‡å·²æ˜¯Base64æ ¼å¼ï¼Œæå–çº¯æ•°æ®')
        const base64Match = imageUrl.match(/;base64,(.+)$/)
        if (base64Match) {
          return base64Match[1] // è¿”å›çº¯Base64æ•°æ®ï¼Œä¸åŒ…å«data:image/xxx;base64,å‰ç¼€
        } else {
          console.error('[AI] Base64æ ¼å¼ä¸æ­£ç¡®:', imageUrl.substring(0, 100) + '...')
          return null
        }
      }

      // å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œè¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºçº¯Base64
      if (imageUrl.startsWith('/static/')) {
        const filePath = path.resolve(process.cwd(), imageUrl.substring(1))
        console.log('[AI] è¯»å–æœ¬åœ°å›¾ç‰‡æ–‡ä»¶:', filePath)

        if (!fs.existsSync(filePath)) {
          console.error('[AI] å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨:', filePath)
          return null
        }

        const imageBuffer = fs.readFileSync(filePath)
        const base64Data = imageBuffer.toString('base64') // çº¯Base64æ•°æ®ï¼Œä¸åŒ…å«å‰ç¼€

        console.log(`[AI] DeepSeekæ ¼å¼å›¾ç‰‡è½¬æ¢æˆåŠŸ - æ–‡ä»¶å¤§å°: ${imageBuffer.length} å­—èŠ‚, Base64é•¿åº¦: ${base64Data.length}`)
        return base64Data
      }

      // å¦‚æœæ˜¯HTTP URLï¼Œæš‚ä¸æ”¯æŒ
      console.warn('[AI] æš‚ä¸æ”¯æŒHTTPå›¾ç‰‡URL:', imageUrl)
      return null

    } catch (error: any) {
      console.error('[AI] DeepSeekæ ¼å¼å›¾ç‰‡å¤„ç†å¤±è´¥:', error.message)
      return null
    }
  }

  /**
   * å¤„ç†å›¾ç‰‡è½¬æ¢ä¸ºBase64æ ¼å¼ï¼ˆä¿ç•™åŸæ–¹æ³•ç”¨äºå…¶ä»–ç”¨é€”ï¼‰
   * æ”¯æŒæœ¬åœ°æ–‡ä»¶è·¯å¾„å’ŒBase64æ•°æ®
   * @param imageUrl å›¾ç‰‡URLæˆ–è·¯å¾„
   * @param mimeType MIMEç±»å‹
   * @param compress æ˜¯å¦å¯ç”¨å‹ç¼©ï¼ˆç”¨äºæµå¼æ¨¡å¼ï¼‰
   */
  private async processImageToBase64(imageUrl: string, mimeType: string, compress: boolean = false): Promise<string | null> {
    try {
      // å¦‚æœå·²ç»æ˜¯Base64æ ¼å¼ï¼ŒéªŒè¯å¹¶è¿”å›
      if (imageUrl.startsWith('data:')) {
        console.log('[AI] å›¾ç‰‡å·²æ˜¯Base64æ ¼å¼ï¼ŒéªŒè¯æ ¼å¼')
        // éªŒè¯Base64æ ¼å¼æ˜¯å¦æ­£ç¡®
        if (imageUrl.includes(';base64,')) {
          return imageUrl
        } else {
          console.error('[AI] Base64æ ¼å¼ä¸æ­£ç¡®:', imageUrl.substring(0, 100) + '...')
          return null
        }
      }

      // å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œè¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºBase64
      if (imageUrl.startsWith('/static/')) {
        const filePath = path.resolve(process.cwd(), imageUrl.substring(1)) // ç§»é™¤å¼€å¤´çš„ '/'
        console.log('[AI] è¯»å–æœ¬åœ°å›¾ç‰‡æ–‡ä»¶:', filePath)

        if (!fs.existsSync(filePath)) {
          console.error('[AI] å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨:', filePath)
          return null
        }

        let imageBuffer = fs.readFileSync(filePath)

        // æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹
        let actualMimeType = mimeType
        if (!actualMimeType || actualMimeType === 'application/octet-stream') {
          const ext = path.extname(filePath).toLowerCase()
          switch (ext) {
            case '.jpg':
            case '.jpeg':
              actualMimeType = 'image/jpeg'
              break
            case '.png':
              actualMimeType = 'image/png'
              break
            case '.gif':
              actualMimeType = 'image/gif'
              break
            case '.webp':
              actualMimeType = 'image/webp'
              break
            default:
              actualMimeType = 'image/jpeg' // é»˜è®¤
          }
        }

        // å¦‚æœå¯ç”¨å‹ç¼©ä¸”æ–‡ä»¶è¾ƒå¤§ï¼Œè¿›è¡Œç®€å•çš„è´¨é‡å‹ç¼©
        if (compress && imageBuffer.length > 1024 * 1024) { // å¤§äº1MBæ—¶å‹ç¼©
          console.log(`[AI] å›¾ç‰‡è¾ƒå¤§(${(imageBuffer.length/1024/1024).toFixed(1)}MB)ï¼Œå¯ç”¨å‹ç¼©æ¨¡å¼`)
          // æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…å‹ç¼©éœ€è¦å›¾ç‰‡å¤„ç†åº“å¦‚sharp
          // å½“å‰ä»…é€šè¿‡é™ä½detailå‚æ•°æ¥å‡å°‘å¤„ç†å¤æ‚åº¦
        }

        const base64 = imageBuffer.toString('base64')
        const dataUrl = `data:${actualMimeType};base64,${base64}`

        const compressionInfo = compress ? ' (å‹ç¼©æ¨¡å¼)' : ''
        console.log(`[AI] å›¾ç‰‡è½¬æ¢æˆåŠŸ${compressionInfo} - æ–‡ä»¶å¤§å°: ${imageBuffer.length} å­—èŠ‚, MIME: ${actualMimeType}, Base64é•¿åº¦: ${base64.length}`)
        return dataUrl
      }

      // å¦‚æœæ˜¯HTTP URLï¼Œæš‚ä¸æ”¯æŒï¼ˆå¯ä»¥åç»­æ‰©å±•ï¼‰
      console.warn('[AI] æš‚ä¸æ”¯æŒHTTPå›¾ç‰‡URL:', imageUrl)
      return null

    } catch (error: any) {
      console.error('[AI] å›¾ç‰‡å¤„ç†å¤±è´¥:', error.message)
      return null
    }
  }

  /**
   * æ™ºèƒ½é€‰æ‹©èŠå¤©æ–¹æ³•
   * æ ¹æ®æ˜¯å¦æœ‰å›¾ç‰‡è‡ªåŠ¨é€‰æ‹©æ–‡æœ¬èŠå¤©æˆ–å¤šæ¨¡æ€èŠå¤©
   */
  public async smartChat(
    message: string,
    images: ImageData[] = [],
    conversationId?: string
  ): Promise<{ reply: string; conversationId: string }> {
    // å¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨å¤šæ¨¡æ€èŠå¤©
    if (images && images.length > 0) {
      return this.chatWithImages(message, images, conversationId)
    }

    // å¦åˆ™ä½¿ç”¨æ™®é€šæ–‡æœ¬èŠå¤©
    return this.chat(message, conversationId)
  }

  /**
   * æ™ºèƒ½é€‰æ‹©æµå¼èŠå¤©æ–¹æ³•
   * æ ¹æ®æ˜¯å¦æœ‰å›¾ç‰‡è‡ªåŠ¨é€‰æ‹©æ–‡æœ¬èŠå¤©æˆ–å¤šæ¨¡æ€èŠå¤©
   */
  public async smartStreamChat(
    message: string,
    images: ImageData[] = [],
    onDelta: (text: string) => void,
    opts?: { signal?: AbortSignal }
  ): Promise<{ conversationId: string }> {
    // å¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨æµå¼å¤šæ¨¡æ€èŠå¤©
    if (images && images.length > 0) {
      return this.streamChatWithImages(message, images, onDelta, opts)
    }

    // å¦åˆ™ä½¿ç”¨æ™®é€šæµå¼æ–‡æœ¬èŠå¤©
    return this.streamChat(message, onDelta, opts)
  }
}
